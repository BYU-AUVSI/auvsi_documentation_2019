\documentclass[]{auvsi_doc}
\setkeys{auvsi_doc.cls}{
	AUVSITitle={Vision Server Description},
	AUVSILogoPath={./../../_resources_/logo.pdf}
}

% include extra packages, if needed
\usepackage{parskip}
\usepackage[space]{grffile}
\usepackage{pdfpages}
\usepackage{hyperref}
\newcounter{includepdfpage}

\newcommand{\pdflinkdoc}[2]{
\includepdf[pages=-,link,offset=25mm -30mm,linkname=#1,pagecommand={\refstepcounter{includepdfpage}\label{#1.\theincludepdfpage}}]{#2}
}

\begin{document}

\begin{AUVSITitlePage}
\begin{artifacttable}
\entry{IM-005, 1.0, 12-11-2018, Initial release, Tyler Miller \& Connor Olsen, Derek Knowles}
% additional \entry{} commands for extra rows in the revision table, if needed
\end{artifacttable}
\end{AUVSITitlePage}

\section{Introduction}

Visions imaging server will be the central interface between the raw data received from the plane 
the various ODLC clients. Below is a brief overview of how it is setup and where its various components reside.

\section{Motivation}

This major code change was primarily motivated by using last years imaging
software and observing its shortcomings. Last years software required overly 
complex and difficult configuration and setup in order to produce actionable 
manual classifications. Manual classification  required 3-4 people, when it 
could be easily managed by 1 or 2. Finally, the system was fully dependent 
on ROS and was interconnected in such a way that it would be next to impossible to change
a single module without the entire package being affected.

Given these shortcomings we set out to create an imaging package that emphasized
the following:

1. Support up to N manual and autonomous imaging clients out of the box with no 
special configuration required.

2. Maximize modularity and transferability by separating the platform from ROS as 
much as possible.

3. Provide extensive documentation to ease future development and enable new developers
to learn quickly.

4. Build and release the code base in such a way that it can be run using a single command
on any platform.

\section{Server}

Once we fully understood last years imaging system we were able to lay out its weaknesses
and create the above objectives to best address them. One of our main concerns was how the 
current codebase spread its information across multiple machines: one machine would hold 
the raw images from the plane's camera, another would hold cropped images, and still another
would hold classification information. With these objectives and shortcomings in mind, a 
basic server-client architecture was defined as shown in Figure \ref{fig:serverFlow}.

\AUVSIFigure
{./figs/serverFlowchart.pdf}
{\textwidth}
{Server Architecture}
{fig:serverFlow}

Notice that the ROS Ingester is the only code block dependent on ROS. In reality, the
ingester is a simple 100 line python script which subscribes to the relavent ROS data
streams (aka: rostopics), and pushes their information into the database.

Model classes represent a single row in a table and essentially function as a translation
layer between the database and the top level ingester/Rest API. 

DAO's or Database Access Objects, interact directly with the database by encapsulating
SQL queries into methods that can be easily accessed and called by external modules.
These methods return model classes or require them as parameters.

For the database we chose Postgresql. Postgres is well known for its powerful
feature set, as well as easy out-of-the-box concurrency safety. The later was particularly
important in our application since there will often be multiple connections simultaneously 
querying most of the database.

Rest APIs are a ubiquitous interface and fit Vision's problem space well. By publishing a
Rest server and building our package around its ideology, support for up to N clients comes
naturally. 

The basic data flow of all these components is shown in Figure \ref{fig:dataFlow}. Note
colored rectangles represent tables, squiggly boxes represent client side actions,
and gray boxes represent server-side functionality.

\AUVSIFigure
{./figs/dataFlow.pdf}
{\textwidth}
{AUVSI Imaging Data Flow Through Autonomous/Manual Classification}
{fig:dataFlow}

Data flows back and forth between client and server, with server holding the definitive-final
copy of an image classification, as well as a history of its state during intermediate steps.
Each sql table shown in Figure \ref{fig:dataFlow} has a corresponding DAO and model class,
making it easy to localize bugs when specific issues arise. Last year's team had particular
difficulty getting their geolocation algorithm to function accurately. This is partially 
because they would simply use the last gps measurement they received, failing to take 
into account camera or transmission delays. By keeping a record of all received gps and 
state measurements, we can calculate a geolocation offset and retrieve old measurements,
allowing for a more accurate model.

\section{Conclusion}

Properly implemented, the server infrastructure allows simple one click installation
for anyone looking to run imaging. Coupled with the vision team's emphasis on comprehensive
documentation and official code releases, the imaging codebase will be as transferable as 
possible for future AUVSI team members.

Besides this high degree of transferability, this design is also modular. Different 
portions of the codebase could be re-implemented or changed with little to no effect on 
other code modules. The strengths of the new imaging model respond to some of the largest
issues in the old imaging codebase and create a reliable, easy to use, modular solution
to AUVSI's imaging problem

\end{document}
